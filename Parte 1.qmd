---
title: "Banco de dados: Boston House Prices"
author: "Fernado Bispo, Jeff Caponero"
format:
    pdf:
      toc: true
      toc-title: Sumário
      colorlinks: true
      documentclass: report
      papersize: letter
      number-sections: false
      geometry:
        - top=30mm
        - left=30mm
        - right=20mm
        - bottom=20mm
        - heightrounded
      fig-pos: "H"
      fig-align: center
      lang: pt-BR
      # fontfamily: libertinus
      fontsize: 12pt
      include-in-header:
      - text: |
          \usepackage{caption}
          \usepackage{fontspec}
          \usepackage{xcolor}
          \usepackage{indentfirst}
          \captionsetup[table]{name=Tabela}
---

```{r pacotes&dados}
#| echo: false
#| warning: false


# PACOTES ----

if (!require(pacman))
  install.packages("pacman")
library(pacman)

pacman::p_load(tidyverse,  janitor, stargazer,  sjmisc, summarytools,
               kableExtra, moments, ggpubr, formattable, gridExtra, 
               glue, corrplot, sessioninfo, readxl, writexl, ggthemes,
               patchwork,  plotly, lmtest, olsrr, gglm, ggplot2,
               tidymodels, GGally, skimr, performance)

dados <- read.csv("boston.csv")

## Arrumação ----
dados <- dados|>
  janitor::clean_names()

dados <- dados|>
  mutate(
    chas = forcats::as_factor(chas),
    rad = forcats::as_factor(rad))
``` 


# Introdução

A busca pela moradia própria é o desejo da grande maioria das pessoas, contudo a conquista desse bem nos grandes centros não é tarefa fácil. Levando isso em consideração a procura por imóveis na região metropolitana torna-se uma opção viável economicamente, mesmo havendo penalizações no que diz respeito a distância e congestionamentos.

O objetivo deste relatório é trazer a luz as análises e conclusões acerca da utilização das técnicas de regressão linear a fim de determinar o preço das casas em Boston, baseado nos dados fornecidos pelo conjunto de dados obtido. Neste primeiro momento, em que se utilizará a regressão linear simples, se buscará determinar uma função que descreva a relação entre o Valor Médio dos imóveis e o Percentual da população de "classe baixa".

Composto por 506 observações e 14 variáveis, o conjunto de dados, publicado no *Jornal of Environmental Economics & Management*, vol.5, 81-102, 1978.t, traz inúmeras características que servirão de parâmetros para resolução do seguinte questionamento: O valor médio dos imóveis é influenciado pelas diversas características externas observadas?

# Metodologia

## Sobre o conjunto de dados

Os dados de preços de 506 casas em Boston, publicados em Harrison, D. and Rubinfeld, D.L. [*'Hedonic prices and the demand for clean air'*](https://www.researchgate.net/profile/Daniel-Rubinfeld/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air/links/5c38ce85458515a4c71e3a64/Hedonic-housing-prices-and-the-demand-for-clean-air.pdf), J. Environ. Economics & Management, vol.5, 81-102, 1978.

Usado em Belsley, Kuh & Welsch, [*'Regression diagnostics: identifying influential data and sources of collinearity.*](https://www.wiley.com/en-us/Regression+Diagnostics%3A+Identifying+Influential+Data+and+Sources+of+Collinearity-p-9780471691174) New York: Wiley 1980.
Os dados podem ser acessados na plataforma para aprendizado de ciência de dados [Kaggle](https://www.kaggle.com/datasets/fedesoriano/the-boston-houseprice-data) através do link:

<https://www.kaggle.com/datasets/fedesoriano/the-boston-houseprice-data>.  

### Variáveis a serem analisadas

A amostra contêm 14 atributos de casas em diferentes locais nos subúrbios de Boston no final dos anos 1970, sendo duas delas classificadas como categóricas e 12 como numéricas. O objetivo é o valor médio das casas em um local (em k$).
As variáveis presentes no banco de dados são descritas a seguir bem como a forma que estas variáveis serão representadas ao longo deste relatório a fim de facilitar o entendimento:


1. CRIM: Índice de criminalidade per capita por bairro.
Taxa de criminalidade por cidade. Uma vez que o CRIM mede a ameaça ao bem-estar que as famílias percebem em vários bairros da área metropolitana de Boston (assumindo que as taxas de criminalidade são geralmente proporcionais às percepções de perigo das pessoas), ele deve ter um efeito negativo nos valores das moradias. Será representada como **Índice Criminalidade**.

2. ZN: Proporção da área residencial de uma cidade dividida em lotes com mais de 25.000 pés quadrados. Uma vez que tal zoneamento restringe a construção de pequenas casas em lotes, esperamos que o ZS esteja positivamente relacionado aos valores das moradias. Um coeficiente positivo também pode surgir porque o zoneamento representa a exclusividade, a classe social e as comodidades externas de uma comunidade. Será representada como **Prop. Terreno Zoneado**.

3. INDUS: Proporção de hectares de negócios não varejistas por bairro. O INDUS serve como um *proxy* para as externalidades associadas ao ruído da indústria, tráfego intenso e efeitos visuais desagradáveis e, portanto, deve afetar negativamente os valores das habitações. Será representado por **Área Industrial**.

4. CHAS: Variável fictícia categórica que representa imóveis próximos a margem do rio Charles (1 se o trecho margeia o rio; 0 caso contrário). Será representada como **Margem**.

5. NOX: Concentração de óxidos nítricos em pphm (partes por 100 milhões). Será representada como **Índice Oxido Nítrico**.

6. RM: Número médio de quartos em unidades proprietárias. RM representa espaço e, em certo sentido, quantidade de habitação. Deve estar positivamente relacionado com o valor da habitação. Verificou-se que a forma RM² fornece um ajuste melhor do que as formas linear ou logarítnica. Será representada por **N° de Cômodos**.

7. AGE: Proporção de unidades próprias construídas antes de 1940. A idade da unidade geralmente está relacionada à qualidade da estrutura. Será representada por **Idade**

8. DIS: Distâncias ponderadas para cinco centros de emprego  na região de Boston. De acordo com as teorias tradicionais de gradientes de renda da terra urbana, os valores das moradias devem ser maiores perto de locatários de emprego. DIS é inserido na forma logarítmica; o sinal esperado é negativo. Será representada como **Dist. Empregos**.

9. RAD: Variável categórica que representa o índice de acessibilidade às rodovias radiais. O índice de acesso rodoviário foi calculado com base na cidade. Boas variáveis de área de estrada são necessárias para que todas as variáveis de poluição não capturem as vantagens locacionais de estradas. O RAD captura outros tipos de vantagens locacionais além da proximidade do local de trabalho. é inserido na forma logarítmica; o sinal esperado é positivo. Será representada como **Acessibilidade Rodovias**.

10. TAX: Valor total do imposto sobre a propriedade ($/$10,000). Mede o custo dos serviços públicos na comunidade terrestre. As taxas de imposto nominais foram corrigidas pelos índices de avaliação locais para gerar o valor total da taxa de imposto para cada cidade. Diferenças intramunicipais na taxa de avaliação eram difíceis de obter e, portanto, não eram usadas. O coeficiente desta variável deve ser negativo.
Será representada como **Imposto**.

11. PTRATIO: Proporção aluno-professor por distrito escolar da cidade. Mede os benefícios do setor público em cada cidade. A relação do rácio aluno-professor com a qualidade da escola não é totalmente clara, embora um rácio baixo deva significar que cada aluno recebe mais atenção individual. Esperamos o sinal em PTRATIO seja negativo. Será representada como **Prop. Prof.-Aluno**.

12. B: O resultado da equação $B=1000(Bk - 0,63)^2$ onde $Bk$ é a proporção de negros por bairro. Em níveis baixos a moderados de B, um aumento em B deve ter uma influência negativa no valor da habitação se os negros forem considerados vizinhos indesejáveis pelos brancos. No entanto, a discriminação de mercado significa que os valores das moradias são mais altos em níveis muito altos de B. Espera-se, portanto, uma relação parabólica entre a proporção de negros em um bairro e os valores das moradias. Será representada por **Prop. Negros/bairro**.

13. LSTAT: Proporção da população de "classe baixa", ou seja, com status inferior = 1/2 (proporção de adultos sem nível de ensino médio e proporção de trabalhadores do sexo masculino classificados como trabalhadores). A especificação logarítmica implica que as distinções de status socioeconômico significam mais nas camadas superiores da sociedade do que nas classes inferiores. Será representada por **Pop. Classe Baixa**.


### Variável de Saída (Resposta):
- Valor do Imóvel: Valor médio de residências ocupadas pelo proprietário em US\$1.000 [k\$].  

### Fonte

StatLib - Carnegie Mellon University


# Resultados

## Análise Descritiva

De modo a conhecer melhor o banco de dados analisado é importante realizar uma análise descritiva das variáveis que o compõem. Na Tabela 1 pode se ver as medidas de resumo de posição e de tendência central destas variáveis.

```{r}
#| echo: false
#| warning: false
#| 


# setwd("~/Dropbox/Estatística/StatisticWorks/Boston_House_Prices")
# set.seed(7)

```



```{r tab1:medidas_resumo}
#| echo: false
#| warning: false

# Medidas Resumo ----
summarytools::st_options(lang = "pt")

dados|>
  # select(-b, - rad, -zn)|>
  rename(
    "Idade do Imóvel" = age, "Índice Criminalidade" = crim, "Dist. Empregos" = dis, "Área Industrial" = indus,
    "Pop. Classe Baixa" = lstat, "Índice Oxido Nítrico" = nox, "Prop. Prof.-Aluno" = ptratio,
    "N° Cômodos" = rm, "Imposto Propriedade" = tax, "Valor do Imóvel" = medv, "Acessibilidade Rodovias" = rad, "Prop. Terreno Zoneado" = zn, "Prop. Negros/bairro" = b
  )|>
  summarytools::descr(
    stats = c("min", "q1", "med", "mean","q3", "max",  "sd", "cv", "Skewness", "Kurtosis"),
    justify = "c",
    style = "rmarkdown",
    transpose = T
  )|>
    kbl(
    caption = "Medidas Resumo dos dados",
    digits = 2,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", row.names = T, booktabs = T
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "scale_down", "repeat_header")
  )|>
  column_spec(1, bold = T
              )|>
  kable_material()

```


Para facilitar a compreenção das medidas apresentadas na Tabela 1, a Figura 1 mostra graficamente estas distribuições.


```{r fig1:Histograma}
#| echo: false
#| warning: false
#| fig-height: 9
#| fig-width: 7

# Histograma ----
{
## g1 age ----
g1 <- dados|>
  ggplot() +
  aes(x = age) +
  geom_histogram(
    aes(y = ..density..),
    bins = 40,
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Unidades constuídas antes \nde 1940",
    x = "Proporção",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g2 crim ----
g2 <- dados|>
  ggplot() +
  aes(x = crim) +
  geom_histogram(
    aes(y = ..density..),
    fill = "lightblue",
    colour = "darkblue",
    # binwidth = 2
    bins = 45
    ) +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Índice de Criminalidade",
    x = "Índice",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g3 dis ----
g3 <- dados|>
  ggplot() +
  aes(x = dis) +
  geom_histogram(
    aes(y = ..density..),
    bins = 45,
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_x_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Distância para cinco centros \nde emprego.",
    x = "Distâncias Ponderadas",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g4 indus ----
g4 <- dados|>
  ggplot() +
  aes(x = indus) +
  geom_histogram(
    aes(y = ..density..),
    bins = 40,
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Negócios não varejistas \npor bairro",
    x = "Proporção de hectares ocupados",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g5 lstat ----
g5 <- dados|>
  ggplot() +
  aes(x = lstat) +
  geom_histogram(
    aes(y = ..density..),
    bins = 40,
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = 'População de "classe baixa"',
    x = 'Percentual',
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g6 medv ----
g6 <- dados|>
  ggplot() +
  aes(x = medv) +
  geom_histogram(
    aes(y = ..density..),
    bins = 35,
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Valor médio de residências \nocupadas",
    x = "Valor Médio",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g7 nox ----
g7 <- dados|>
  ggplot() +
  aes(x = nox) +
  geom_histogram(
    aes(y = ..density..),
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Concentração de Óxidos \nNitricos (NO)",
    x = "Partes por 10 milhões",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g8 ptratio ----
g8 <- dados|>
  ggplot() +
  aes(x = ptratio) +
  geom_histogram(
    aes(y = ..density..),
    bins = 30,
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_x_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Aluno/Professor por bairro",
    x = "Proporção",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g9 rm ----
g9 <- dados|>
  ggplot() +
  aes(x = rm) +
  geom_histogram(
    aes(y = ..density..),
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Número médio de cômodos por \nhabitação",
    x = "Quantidade",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g10 tax ----
g10 <- dados|>
  ggplot() +
  aes(x = tax) +
  geom_histogram(
    aes(y = ..density..),
    bins = 35,
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Taxa de imposto predial",
    x = "Valor por $10.000",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g11 zn ----
g11 <- dados|>
  ggplot() +
  aes(x = zn) +
  geom_histogram(
    aes(y = ..density..),
    bins = 35,
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Proporção de Terreno Zoneado",
    x = "Proporção de Terreno",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## g12 b ----
g12 <- dados|>
  ggplot() +
  aes(x = b) +
  geom_histogram(
    aes(y = ..density..),
    bins = 35,
    fill = "lightblue",
    colour = "darkblue") +
  geom_density(
    alpha = 0.2,
    fill = "blue",
    colour = "blue") +
  scale_y_continuous(
    labels = scales::number_format(
      big.mark = ".",
      decimal.mark = ","
    )) +
  labs(
    title = "Proporção de Negros por bairro",
    x = "Proporção",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

g1 + g2 + g3 + g4 + g5 + g6 + g7 + g8 + g9 + g10 + g11 + g12 + 
  plot_layout(ncol = 3) + 
  plot_annotation(
    title = "Figura 1: Histogramas das variáveis em análise.",
    caption = "Fonte: StatLib - Carnegie Mellon University",
    tag_levels = c("A", "1"), tag_prefix = "Sub Fig. ", tag_sep = ".",
    tag_suffix = ":") &
  theme(
    plot.tag.position = c(0, 1),
    plot.tag = element_text(size = 5.5, hjust = 0, vjust = -0.4))
}
```


Desta análise inicial, destancam-se algumas características:

- O Índice de criminalidade per capita por bairro é bastante baixo na maioria dos bairros (Sub.Fig B);
- A Proporção de terreno residencial zoneada para lotes acima de 25.000 sq.ft. contém uma alta concentração de valores zeros (Sub.Fig K);
- Verifica-se uma concentração de empresas com cerca de 18 hectares em diversos bairros (Sub.Fig D);
- Há uma concentração de imóveis com alto valor total do imposto predial (Sub.Fig J);
- A maior parte dos bairros tinha alta proporção de negros (Sub.Fig L). 


Tendo em vista o fato de as variáveis categóricas não estarem representadas na Figura 1, foi construída a figura 2 com gráficos que possibilitam a avaliação do comportamento dessas variáveis de maneira mais adequada.

```{r fig2:Grafico_Barras+Rosca}
#| echo: false
#| warning: false
#| fig-height: 6
#| fig-width: 7

p1 <- dados|>
  ggplot(aes(x = rad, y = after_stat(count)/sum(after_stat(count))))+
  geom_bar(fill = "darkblue")+ 
  geom_text(
    aes(
      label = scales::percent((after_stat(count))/sum(after_stat(count)), big.mark = ".", decimal.mark = ","),
      y = after_stat(count)/sum(after_stat(count))),
    stat = "count", vjust = -0.2, size = 1.8
  ) +
  labs(
    title = "Índice de Acessibilidade às Rodovias",
    x = "Índice",
    y = "Frequência Relativa"
  )+
  scale_y_continuous(labels = scales::percent)+
  scale_x_discrete(limits = c(1:25))+
  theme_minimal()+
    theme(
    legend.position = "none", title = element_text(size = 7.5))

p2 <- dados %>% 
  count(chas) %>%
  mutate(
    tipo = case_when(
      chas == "0" ~ "Não Margeiam o rio",
      chas == "1" ~ "Margeiam o rio"),
    pct = round(prop.table(n)*100, 2), 
    rotulo = glue::glue('{tipo}\n{n} ({pct}%)')) %>% 
  ggpubr::ggdonutchart(., "pct", 
                       label = "rotulo", lab.pos = "out",
                       lab.font = c(3, "plain", "black"),
                       fill = "chas",  color = "white",
                       palette = c("darkblue", "skyblue"))+
  labs(
    title = "Imóveis que margeiam o Rio Charles"
  )+
  theme(
    legend.position = "none", title = element_text(size = 7.5)
  )

p1 + p2 +
  plot_layout(nrow = 2, widths = 3) +
  plot_annotation(
    title = "Figura 2: Distribuição de Frequência das Variáveis Categóricas.",
    caption = "Fonte: StatLib - Carnegie Mellon University",
    tag_levels = c("A", "1"), tag_prefix = "Sub Fig. ", tag_sep = ".",
    tag_suffix = ":") &
  theme(
    plot.tag.position = c(0, 1),
    plot.tag = element_text(size = 5.5, hjust = 0, vjust = -0.4))

```


Avaliando a Figura 2 é possível constatar na Sub.Fig A que representa a frequência do Índice de Acessibilidade às Rodovias a existência de um comportamento tri modal e que há uma lacuna entre os índices, sendo este *gap* entre o índice 8 e o índice 24 indicando assim que há uma concentração de imóveis próximos a acessos a rodovias e que há uma parcela, cerca de 26%, que estão distantes desses acessos, podendo pressupor que esses imóveis são desvalorizados em relação aos mais próximos.

A Sub.Fig B que retrata os Imóveis que margeiam o Rio Charles é possível identificar que mais de 93% não margeiam o rio, apenas uma pequena parcela margeia, podendo pressupor uma maior valorização dos imóveis que margeiam o rio.


## Análise de Dados Atípicos

Com base na variável que indica se o imóvel margeia ou não o Charles River, pode-se realizar a análise de disperção dos dados por meio de gráficos do tipo BoxPlot, como se vê na Figura 1.

```{r fig3:BoxPlot}
#| echo: false
#| warning: false
#| fig-height: 9
#| fig-width: 7

# BoxPlot ----
{
## b1 age ----
b1 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = age)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Unidades constuídas antes \nde 1940",
    x = "Posição",
    y = "Proporção antes de 1940"
  )+theme_minimal(base_size = 7.5)

## b2 crim ----
b2 <- dados|>
  mutate(
    chas = lvls_revalue(chas, c("Na Margem", "Afastado"))
  )|>
  ggplot(aes(x = chas, y = crim)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Índice de Criminalidade",
    x = "Posição",
    y = "Índice"
  )+theme_minimal(base_size = 7.5)

## b3 dis ----
b3 <- dados|>
  mutate( chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = dis)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Distância para cinco centros \nde emprego.",
    x = "Posição",
    y = "Distâncias Ponderadas"
  ) +
  scale_y_continuous(
    labels = scales::number_format(
      dig.mark = ".",
      decimal.mark = ",")
    )+theme_minimal(base_size = 7.5)
      
## b4 indus ----
b4 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = indus)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Negócios não varejistas \npor bairro",
    x = "Proporção de hectares ocupados",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## b5 lstat ----
b5 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = lstat)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = 'População de "classe baixa"',
    x = "Posição",
    y = "Percentual"
  )+theme_minimal(base_size = 7.5)

## b6 medv ----
b6 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = medv)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Valor médio de residências \nocupadas",
    x = "Posição",
    y = "Valor médio"
  )+theme_minimal(base_size = 7.5)

## b7 nox ----
b7 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = nox)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Concentração de Óxidos \nNitricos (NO)",
    x = "Posição",
    y = "Partes por 10 milhões"
  ) +
  scale_y_continuous(
    labels = scales::number_format(
      dig.mark = ".",
      decimal.mark = ",")
    )+theme_minimal(base_size = 7.5)

## b8 ptratio ----
b8 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = ptratio)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Aluno/Professor por bairro",
    x = "Posição",
    y = "Proporção"
  ) +
  scale_y_continuous(
    labels = scales::number_format(
      dig.mark = ".",
      decimal.mark = ",")
    )+theme_minimal(base_size = 7.5)

## b9 rm ----
b9 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = rm)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Número médio de cômodos por \nhabitação",
    x = "Posição",
    y = "Quantidade"
  )+theme_minimal(base_size = 7.5)

## b10 tax ---- 
b10 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = tax)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Taxa de imposto predial",
    x = "Posição",
    y = "Valor por $10.000"
  )+theme_minimal(base_size = 7.5)

## b11 zn ---- 
b11 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = zn)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Proporção de Terreno Zoneado",
    x = "Proporção de Terreno",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

## b12 b ---- 
b12 <- dados|>
  mutate(chas = lvls_revalue(chas, c("Na Margem", "Afastado")))|>
  ggplot(aes(x = chas, y = b)) +
  geom_boxplot(col="darkblue", fill="skyblue", alpha = 0.5)+
  labs(
    title = "Proporção de Negros por bairro",
    x = "Proporção",
    y = "Densidade"
  )+theme_minimal(base_size = 7.5)

b1 + b2 + b3 + b4 + b5 + b6 + b7 + b8 + b9 + b10 + b11 + b12 +  
  plot_layout(ncol = 3) + 
  plot_annotation(
    title = "Figura 3: BoxPlot das variáveis em análise.",
    caption = "Fonte: StatLib - Carnegie Mellon University",
    # theme = theme_minimal(plot.title = element_text(size = 10)),
    tag_levels = c("A", "1"), tag_prefix = "Sub Fig. ", tag_sep = ".",
    tag_suffix = ":") &
  theme(
    plot.tag.position = c(0, 1),
    plot.tag = element_text(size = 5.5, hjust = 0, vjust = -0.4))
}

```


Pode-se verificar pela Figura 3 que cerca de 2/3 das variáveis apresentam valores atípicos (*outlayers*), entretanto o tratamento destes *outlayers* em todos os casos parece, salvo melhor juízo, ser o mesmo. Observa-se que há coerência entre eles, isto é, são realizações possíveis e não devem ser desprezadas como se fossem erros ou dados irrelevantes. Isto se deve a tremenda variedade em tipos, propósitos e status dos imóveis avaliados. Esses dados por sua vez, representam um maior desafio ao modelamento a que esse trabalho se propõe.

## Relação entre as variáveis 

Antes da proposição do modelo de regressão mais bem elaborado é conveniente uma avaliação gráfica da dispersão dos valores das variáveis em relação à variável resposta **Valor Médio do Imóvel**. A Figura 4 apresenta essas dispersões de pontos e já apresenta uma linha de tendência para os valores observados.


```{r fig4:regressao}
#| echo: false
#| warning: false
#| fig-height: 8
#| fig-width: 7

# Dispersão ----
{
  ## d1 age ----
  d1 <- dados|>
    ggplot(aes(y = medv, x = age)) +
    geom_point(color = "#234B6E")+
    labs(
      title = "Unidades constuídas antes de \n1940",
      y = 'Valor Médio (por $1.000)',
      x = 'Proporção antes de 1940'
    )+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 5, label.y = 7.5, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    scale_y_continuous(
      labels = scales::number_format(
        big.mark = ".",
        decimal.mark = ","
      ))+
    geom_smooth(method=lm, se=T, color="tomato", size = 0.6)+
    theme_minimal(base_size = 7.5)
  
  ## d2 crim ----
  d2 <- dados |>
    ggplot(aes(
      y = medv, 
      x = crim)) +
    geom_point(color = "#234B6E")+
    labs(
      title = 'Índice de Criminalidade',
      y = 'Valor Médio (por $1.000)',
      x = 'Índice'
    )+
    geom_smooth(method=lm, se=T, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 50, label.y = 50, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    theme_minimal(base_size = 7.5)

  ## d3 dis ----
  d3 <- dados |>
    ggplot(aes(
      y = medv, 
      x = dis)) +
    geom_point(color = "#234B6E")+
    labs(
      title = "Distância para cinco centros de \nemprego.",
      y = 'Valor Médio (por $1.000)',
      x = 'Distâncias Ponderadas'
    )+
    geom_smooth(method=lm, se=TRUE, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 9, label.y = 7.5, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    scale_x_continuous(
      labels = scales::number_format(
        big.mark = ".",
        decimal.mark = ","
      ))+
    theme_minimal(base_size = 7.5)
  
  ## d4 indus ----
  d4 <- dados |>
    ggplot(aes(
      y = medv, 
      x = indus)) +
    geom_point(color = "#234B6E")+
    labs(
      title = "Negócios não varejistas por \nbairro",
      y = 'Valor Médio (por $1.000)',
      x = 'Hectares Ocupados'
    )+
    geom_smooth(method=lm, se=TRUE, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 1.5, label.y = 7.5, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    theme_minimal(base_size = 7.5)

  ## d5 lstat ----
  d5 <- dados |>
    ggplot(aes(
      y = medv, 
      x = lstat)) +
    geom_point(color = "#234B6E")+
    labs(
      title = 'População de "classe baixa"',
      y = 'Valor Médio (por $1.000)',
      x = 'Proporção'
    )+
    geom_smooth(method=lm, se=TRUE, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 25, label.y = 47.5, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    theme_minimal(base_size = 7.5)

  ## d6 nox ----
  d6 <- dados |>
    ggplot(aes(
      y = medv, 
      x = nox)) +
    geom_point(color = "#234B6E")+
    labs(
      title = "Concentração de Óxidos \nNitricos (NO)",
      y = 'Valor Médio (por $1.000)',
      x = 'Partes por 10 milhões'
    )+
    geom_smooth(method=lm, se=TRUE, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 0.75, label.y = 47.5, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    scale_x_continuous(
      labels = scales::number_format(
        big.mark = ".",
        decimal.mark = ","
      ))+
    theme_minimal(base_size = 7.5)
  
  ## d7 ptratio ----
  d7 <- dados |>
    ggplot(aes(
      y = medv, 
      x = ptratio)) +
    geom_point(color = "#234B6E")+
    labs(
      title = "Aluno/Professor por bairro",
      y = 'Valor Médio (por $1.000)',
      x = 'Proporção'
    )+
    geom_smooth(method=lm, se=TRUE, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 13, label.y = 7.5, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    scale_x_continuous(
      labels = scales::number_format(
        big.mark = ".",
        decimal.mark = ","
      ))+
    theme_minimal(base_size = 7.5)
  
  ## d8 rm ----
  d8 <- dados |>
    ggplot(aes(
      y = medv, 
      x = rm)) +
    geom_point(color = "#234B6E")+
    labs(
      title = "Número médio de cômodos por \nhabitação",
      y = 'Valor Médio (por $1.000)',
      x = 'Quantidade'
    )+
    geom_smooth(method=lm, se=TRUE, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 3.7, label.y = 45, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    theme_minimal(base_size = 7.5)
  
  ## d9 tax ----
  d9 <- dados |>
    ggplot(aes(
      x = tax, y = medv)) +
    geom_point(color = "#234B6E")+
    labs(
      title = "Taxa de imposto predial",
      y = 'Valor Médio (por $1.000)',
      x = 'Valor por $10.000'
    )+
    geom_smooth(method=lm, se=TRUE, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 200, label.y = 7.5, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    theme_minimal(base_size = 7.5)
  
  ## d10 zn ----
  d10 <- dados |>
    ggplot(aes(
      x = zn, y = medv)) +
    geom_point(color = "#234B6E")+
  labs(
    title = "Proporção de Terreno Zoneado",
    x = "Proporção",
    y = "Densidade"
  )+
    geom_smooth(method=lm, se=TRUE, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 20, label.y = 7.5, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    theme_minimal(base_size = 7.5)
  
  ## d11 b ----
  d11 <- dados |>
    ggplot(aes(
      x = b, y = medv)) +
    geom_point(color = "#234B6E")+
  labs(
    title = "Proporção de Negros por bairro",
    x = "Proporção",
    y = "Densidade"
  )+
    geom_smooth(method=lm, se=TRUE, color="tomato", size = 0.6)+
    ggpubr::stat_cor(
      aes(label = ..r.label..),
      cor.coef.name = c("rho"),
      label.sep = "; ", geom = "text",
      color="tomato", method = "pearson", 
      label.x = 50, label.y = 45, show.legend = F,
      p.accuracy = 0.001, r.accuracy = 0.0001,
      size = 2)+
    theme_minimal(base_size = 7.5)

  d1 + d2 + d3 + d4 + d5 + d6 + d7 + d8 + d9 + d10 + d11 +  
    plot_layout(ncol = 3) + 
    plot_annotation(
      title = "Figura 4: Reta de regressão ajustada entre o Valor médio dos imóveis e \ndemais medições",
      tag_levels = c("A", "1"), tag_prefix = "Sub Fig. ", tag_sep = ".",
      tag_suffix = ":") &
    theme(
      legend.position = "none",
      plot.tag.position = c(0, 1),
      plot.tag = element_text(size = 5.5, hjust = 0, vjust = -0.4))

}
```


Para avaliar a significância das correlações entre as variáveis com  relação ao **Valor Médio do Imóvel** segue a Tabela 2 com os resultados do Teste de Hipóteses com nível de significância de 5% que tem como hipóteses:

$$H_0: \widehat{\rho} = 0$$

$$H_1: \widehat{\rho} \neq 0.$$
```{r tab2:TesteHipo_CorPearson}
#| echo: false
#| warning: false

# Correlação 2 ----

# Cor Test
cortestCrim <- stats::cor.test(dados$medv, dados$crim)
cortestZn <- stats::cor.test(dados$medv, dados$zn)
cortestIndus <- stats::cor.test(dados$medv, dados$indus)
cortestNox <- stats::cor.test(dados$medv, dados$nox)
cortestRm <- stats::cor.test(dados$medv, dados$rm)
cortestAge <- stats::cor.test(dados$medv, dados$age)
cortestDis <- stats::cor.test(dados$medv, dados$dis)
cortestTax <- stats::cor.test(dados$medv, dados$tax)
cortestPtratio <- stats::cor.test(dados$medv, dados$ptratio)
cortestB <- stats::cor.test(dados$medv, dados$b)
cortestLstat <- stats::cor.test(dados$medv, dados$lstat)

# Estatística t
resultados <- rbind(cortestCrim$statistic, 
           cortestZn$statistic, 
           cortestIndus$statistic,
            cortestNox$statistic,
            cortestRm$statistic,
            cortestAge$statistic,
            cortestDis$statistic,
            cortestTax$statistic,
            cortestPtratio$statistic,
            cortestB$statistic,
            cortestLstat$statistic)

# p-valor
aux <- rbind(cortestCrim$p.value,
cortestZn$p.value,
cortestIndus$p.value,
cortestNox$p.value,
cortestRm$p.value,
cortestAge$p.value,
cortestDis$p.value,
cortestTax$p.value,
cortestPtratio$p.value,
cortestB$p.value,
cortestLstat$p.value)

resultados <- cbind(resultados, aux)

# IC
aux <- rbind(cortestCrim$conf.int[1:2],
             cortestZn$conf.int[1:2],
             cortestIndus$conf.int[1:2],
             cortestNox$conf.int[1:2],
             cortestRm$conf.int[1:2],
             cortestAge$conf.int[1:2],
             cortestDis$conf.int[1:2],
             cortestTax$conf.int[1:2],
             cortestPtratio$conf.int[1:2],
             cortestB$conf.int[1:2],
             cortestLstat$conf.int[1:2])

resultados <- cbind(resultados, aux)

rownames(resultados) <- c("Índice Criminalidade", "Prop. Terreno Zoneado", "Área Industrial", "Índice Oxido Nítrico", "N° Cômodos", "Idade do Imóvel", "Dist. Empregos", "Imposto Propriedade", "Prop. Prof.-Aluno", "Prop. Negros/bairro", "Pop. Classe Baixa")
colnames(resultados) <- c("t", "p-valor", "LI", "LS")

resultados|>
  kbl(
    caption = "Teste de Hipótese para Correlação",
    digits = 5,
    format.args=list(big.mark=".", decimal.mark=","),
    align = "c", row.names = T, booktabs = T
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header")
  )|>
  column_spec(1, bold = T
  )|>
  footnote(
    general = "Teste realizado com 5% de significância",
    general_title = "Nota:",
    footnote_as_chunk = T
  )|>
  kable_material()


```


Conforme expresso na Tabela 2, levando em consideração o **p-valor** a Hipótese Nula foi rejeitada, e com 95% de confiança se pode afirmar que **é significativa a relação linear entre todas as variáveis em estudo.**


Na avaliação da Figura 4, observa-se que nenhuma das variáveis tem uma aparente forte correlação com o valor médio dos imóveis. A Tabela 3, apresenta os valores calculados de $\hat \beta_0$ e $\hat\beta_1$ que estimam os valores do modelo $Y_i =\beta_0 + \beta_1X_i + \epsilon_i$ com seus respectivos erros padrão ($\sigma_0$ e $\sigma_1$), além de calcular o p-valor desta regressão linear como forma de identificar a rejeição ou não do modelo proposto. Nesta mesma linha, o valor estimado do Coeficiente de Determinação ($R^2$) também foi calculado.


```{r ajuste_dos_modelos}
#| echo: false
#| warning: false

# Ajuste do Modelo 2 ----

mCrim <- lm(dados$medv~dados$crim)
mIndus <- lm(dados$medv~dados$indus)
mNox <- lm(dados$medv~dados$nox)
mRm <- lm(dados$medv~dados$rm)
mAge <- lm(dados$medv~dados$age)
mDis <- lm(dados$medv~dados$dis)
mTax <- lm(dados$medv~dados$tax)
mPtratio <- lm(dados$medv~dados$ptratio)
mLstat <- lm(dados$medv~dados$lstat)
mZn <- lm(dados$medv~dados$zn)
mB <- lm(dados$medv~dados$b)

# Calculando e armazenando o beta0 e erro padrão0
resultados <-  rbind(
  summary(mCrim)$coefficients[1,],
  summary(mIndus)$coefficients[1,],
  summary(mNox)$coefficients[1,],
  summary(mRm)$coefficients[1,],
  summary(mAge)$coefficients[1,],
  summary(mDis)$coefficients[1,],
  summary(mTax)$coefficients[1,],
  summary(mPtratio)$coefficients[1,],
  summary(mLstat)$coefficients[1,],
  summary(mZn)$coefficients[1,],
  summary(mB)$coefficients[1,])

# Removendo testes
resultados <-  resultados[, -c(3)]

# Calculando e armazenando o beta1 e erro padrão1
aux <-  rbind(
  summary(mCrim)$coefficients[2,],
  summary(mIndus)$coefficients[2,],
  summary(mNox)$coefficients[2,],
  summary(mRm)$coefficients[2,],
  summary(mAge)$coefficients[2,],
  summary(mDis)$coefficients[2,],
  summary(mTax)$coefficients[2,],
  summary(mPtratio)$coefficients[2,],
  summary(mLstat)$coefficients[2,],
  summary(mZn)$coefficients[2,],
  summary(mB)$coefficients[2,])

# Mantém apenas beta1 e o erro padrão
aux <- aux[, -c(3)]

resultados <- cbind(resultados, aux)

# Função para calcular o p-valor
# lmp <- function (modelobject) {
#   if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
#   f <- summary(modelobject)$fstatistic
#   p <- pf(f[1],f[2],f[3],lower.tail=F)
#   attributes(p) <- NULL
#   return(p)
# }
# 
# # Calculando e armazenando o p-valor
# aux <- rbind(
#   lmp(mCrim), lmp(mIndus),
#   lmp(mNox), lmp(mRm), lmp(mAge), 
#   lmp(mDis), lmp(mTax), lmp(mPtratio),
#   lmp(mLstat), lmp(mZn),lmp(mB)
# )

# resultados <- cbind(resultados, aux)

# Calculando e armazenando o Coeficiente de Correlação
aux <-  rbind(
  summary(mCrim)$r.squared,
  summary(mIndus)$r.squared,
  summary(mNox)$r.squared,
  summary(mRm)$r.squared,
  summary(mAge)$r.squared,
  summary(mDis)$r.squared,
  summary(mTax)$r.squared,
  summary(mPtratio)$r.squared,
  summary(mLstat)$r.squared,
  summary(mZn)$r.squared,
  summary(mB)$r.squared)

resultados <- cbind(resultados, aux)

# Inserindo o nome das variáveis (colunas)
rownames(resultados) <- c("Índice Criminalidade", "Área Industrial", "Índice Oxido Nítrico", "N° Cômodos", "Idade do Imóvel", "Dist. Empregos", "Imposto Propriedade", "Prop. Prof.-Aluno", "Pop. Classe Baixa", "Prop. Terreno Zoneado", "Prop. Negros/bairro")

# "Valor do Imóvel" = medv, "Acessibilidade Rodovias" = rad,  = zn,  = b

# Inserindo o nome das linhas
# colnames(resultados) <- c("$\\beta_0$", "$\\sigma_0$", "$\\beta_1$", "$\\sigma_1$", "p-valor", "$R^2$")

```



```{r tab3:modelos_ajustados}
#| echo: false
#| warning: false

# resultados|>
#   kbl(
#     caption = "Valores dos modelos de regressão linear simples.",
#     format.args=list(big.mark=".", decimal.mark=","),
#     digits = 3, align = "c", row.names = T, booktabs = T,
#     escape = FALSE,
#   )|>
#   kable_styling(
#     full_width = F, position = 'center', 
#     latex_options = c("striped", "HOLD_position", "repeat_header")
#   )|>
#   column_spec(1, bold = T
#   )|>
#   kable_material()


resultados|>
  kbl(
    caption = "Sumarização dos Modelos Ajustados de Regressão Linear Simples - RLS.",
    format.args=list(big.mark=".", decimal.mark=","),
    digits = 3, align = "c", row.names = T, booktabs = T,
    escape = FALSE,
    col.names = c("Estimativa", "Erro Padrão", "p-valor", "Estimativa", "Erro Padrão", "p-valor", "$R^2$")
  )|>
  kable_styling(
    full_width = F, position = 'center', 
    latex_options = c("striped", "HOLD_position", "repeat_header", "scale_down")
  )|>
  column_spec(1, bold = T
  )|>
  add_header_above(c(" " = 1, "Sumarização para Beta 0" = 3, "Sumarização para Beta 1" = 3, " " = 1))|>
  kable_material()


```


### Interpretação dos Parâmetros dos Modelos Ajustados

Baseado na análise dos gráficos de dispersão e considerando os modelos ajustados cosntantes na Tabela 3 e a sua ordem de precedência, seguem as interpretações:

- Modelo que avalia o Índice de Criminalidade:
  - Para cada **valorização** de 0,415 no Índice de Criminalidade o Valor Médio dos Imóveis decresce em $24 033,00 ou seja, os imóveis se desvalorizam em regiões cujo Índice de Criminalidade é elevado.
- Modelo que avalia a Área Industrial:
  - O Valor Médio dos Imóveis decresce em $29 755,00 para cada **valorização** proporcional de 0,648 hectares de Negócios não Varejistas.
- Modelo que avalia o Índice Oxido Nítrico:
  - Há uma **desvalorização** de cerca de $41 346,00 no Valor Médio dos Imóveis para cada aumento de 33 916 pphm (partes por 100 milhões) no Índice Oxido Nítrico, ou seja, há uma desvalorização no valor dos imóveis que estão situados em regiões cujo ar é mais poluída.
- Modelo que avalia o N° Cômodos:
  - Há um **valorização** de cerca de $34 671,00 no Valor Médio dos Imóveis para cada aumento de aproximadamente 9 cômodos, ou seja, os imóveis são mais valorizados a medida que possuem mais cômodos.
- Modelo que avalia a Idade do Imóvel:
  - Há uma **desvalorização** de cerca de $30 979,00 para cada aumento proporcional de 0,123 unidades próprias construídas antes de 1940, ou seja, os imóveis são desvalorizados à medida que são mais antigos.
- Modelo que avalia a Dist. Empregos:
  - Há um **valorização** de cerca de $18 390,00 no Valor Médio dos Imóveis à medida que a distância para os centros de emprego na região de Boston aumenta.
- Modelo que avalia o Imposto de Propriedade:
  - Há uma **desvalorização** de cerca de $32 971,00 no Valor Médio dos Imóveis à medida que há um aumento de aproximadamente 0,026 no valor proporcional total do Imposto de Propriedade, ou seja, quanto maior o imposto pago na região, maior a desvalorização do imóvel.
- Modelo que avalia a Prop. Prof.-Aluno:
  - Há uma **desvalorização** de cerca de $62 345,00 no Valor Médio dos Imóveis à medida que há um aumento de aproximadamente 2,157 na proporção professor aluno. Como a própria descrição da variável descreve como confusa essa relação, de fato se mostra, com base no modelo ajustado da variável, pois demostra que os imóveis se desvalorizam a medida que os benefícios do setor público aumentam!
- Modelo que avalia a Pop. Classe Baixa:
  - Há uma **desvalorização** de cerca de $34 554,00 no Valor Médio dos Imóveis à medida que há um aumento de aproximadamente 0,950 na proporção da Pop. de Classe Baixa, ou seja, os imóveis se desvalorizam a medida que a classe social dos habitantes da região cai.
- Modelo que avalia a Prop. Terreno Zoneado:
  - Há um **valorização** de cerca de $20 918,00 no Valor Médio dos Imóveis à medida que há um aumento de aproximadamente 0,142 na Prop. Terreno Zoneado, ou seja, os imóveis são valorizados em regiões com maior proporção de zoneamento.
- Modelo que avalia a Prop. Negros/bairro:
  - Há um **valorização** de cerca de $10 551,00 no Valor Médio dos Imóveis à medida que há um aumento de aproximadamente 0,034 na proporção de Prop. Negros/bairro, ou seja, os imóveis são mais valorizados em regiões cuja proporção de negros é maior.


Tendo em vista que nesse primeiro momento a proposta é a implementação de técnicas de Regressão Linear Simples - RLS, a escolha de uma variável explicativa que aparenta melhor possibilidade de explicação do Preço Médio dos Imóveis se faz necessária. Após análise dos gráficos de dispersão, Coeficiente de Correlação e avaliação dos Coeficientes de Determinação a variável escolhida foi **Pop. Classe Baixa**, logo as análises a seguir serão direcionadas a avaliar o modelo com esta variável.


## Significância do Modelo

Tendo em vista a necessidade de se avaliar a significância dos parâmetros, o teste de hipótese para tal situação será realizado, contendo as seguintes hipóteses:

$$H_0: \hat{\beta_0} = 0$$
$$H_1: \hat{\beta_0} \neq 0.$$

As Tabelas 4  traz os principais resultados da tabela ANOVA e do Intervalo de Confiança para os parâmetros, possibilitando assim inferir com base no teste acima mencionado.

```{r tab4:anova_ic}
#| echo: false
#| warning: false

mLstat <- lm(dados$medv~dados$lstat)

resultados <- cbind(anova(mLstat), confint(mLstat))

rownames(resultados) <- c("β0", "β1")

colnames(resultados) = c("GL", "Soma de \nQuadrados", "Quadrado Médio", "Valor F-Snedecor", "p-valor", "2,5%", "97,5%")

resultados

# resultados %>% 
# kableExtra::kbl(
#   caption = "Análise de Variância (ANOVA) e Intervalos de Confiança \npara os parâmetros estimados no MRLS.",
#   format.args=list(big.mark=".", decimal.mark=","),
#   digits = 3, align = "c", row.names = T, booktabs = T,
#   escape = F
#   # col.names = c("GL", "Soma de Quadrados", "Quadrado Médio", "Estatística F-Snedecor", "p-valor", "α = 2,5%", "(1 - α) = 97,5%")
# ) %>% 
# kableExtra::kable_styling(
#   full_width = F, position = 'center',
#   latex_options = c("striped", "HOLD_position", "repeat_header", "scale_down")
# )
  # column_spec(1, bold = T)|>
  # kable_material()
  # add_header_above(c(" " = 1, "ANOVA" = 5, "Intervalos de Confiança" = 2), bold = T)|>
```


Analisando a Tabela 3, que traz os dados sumarizados dos modelos ajustados, é possível constatar que tanto $\hat{\beta_0}$ quanto $\hat{\beta_1}$ são significantes para todos os modelos ajustados, com base no p-valor.

A Tabela 4, que traz os resultados da tabela ANOVA, para o modelo que avalia o **Valor Médio dos Imóveis** em relação a **Pop. Classe Baixa**, corrobora com a significância do $\hat{\beta_1}$, pois sendo o p-valor menor que o nível de significância ($\alpha$) possibilita rejeitar $H_0$, indicando ser significante para o modelo. O Intervalo de Confiança para os parâmetros estimados, mostra que **com 95% de confiança é possível afirmar que o verdadeiro valor de $\hat{\beta_0}$ está entre (`r glue::glue('({scales::number(confint(mLstat)[1,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mLstat)[1,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')` e que o verdadeiro valor de $\hat{\beta_1}$ está entre (`r glue::glue('({scales::number(confint(mLstat)[2,1], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")}; {scales::number(confint(mLstat)[2,2], accuracy = 0.0001, big.mark = ".", decimal.mark = ",")})')`)**.


## Análise de Resíduos

Sendo de fundamental importância para a verificação da bondade do modelo, a análise de resíduos possibilita avaliar se refletem o comportamento do modelo, para tanto se construiu a Figura 5 para iniciar as análises descritas.

```{r fig5:analise_residuos}
#| echo: false
#| warning: false
#| fig-width: 7
#| fig-height: 3

mFit <- lm(medv~lstat, data = dados)

dados_mFit_resid <- broom::augment(mFit)

# Gráfico de Resíduos contra Valor Médio
d1 <- dados_mFit_resid|>
  ggplot(aes(x = .fitted, y = .resid)) + 
  geom_point(color = "#234B6E") +
  geom_hline(yintercept = 0, linetype = 2, size = 0.2) +
  geom_smooth(
    se = T, color = "tomato", method = 'loess', 
    size = 0.5, formula = 'y ~ x')+
  labs(
    x = "Valores Médios Ajustados",
    y = "Resíduos Ordinários",
    title = "Linearidade"
  )+
  scale_x_continuous(breaks = seq(0,30,5))+
  theme_minimal(base_size = 7.5)+
  theme(legend.position = "none")

## Gráfico de normalidade dos resíduos
d2 <- dados_mFit_resid %>% 
  ggplot(aes(sample = .std.resid)) + 
  qqplotr::stat_qq_band(alpha = 0.3) +
  qqplotr::stat_qq_point(color = "#234B6E") +
  qqplotr::stat_qq_line(linetype = 1, size = 0.5, color = "tomato") +
  labs(
    x = "Quantil Teórico",
    y = "Quantil Amostral",
    title = "Normalidade dos Resíduos"
  )+
  scale_x_continuous(breaks = seq(-3,3,1))+
  theme_minimal(base_size = 7.5)

d1+d2 + plot_annotation(
  title = "Figura 5: Análise de resíduos do modelo ajustado",
  tag_levels = c("A", "1"), tag_prefix = "Sub Fig. ",
  tag_sep = ".", tag_suffix = ":") &
  theme(
    legend.position = "none",
    plot.tag.position = c(0, 1),
    plot.tag = element_text(size = 5.5, hjust = 0, vjust = -0.4)
  )

```



Analisando a Figura 5, Sub.Fig. A, que traz o gráfico que avalia a **linearidade** do modelo se constata uma não aleatoriedade, possibilitando identificar um certo padrão, aparentando um afunilamento dos dados, indicando assim uma variância não constante (pela mudança da amplitude dos dados), em que mostra uma menor variabilidade dos resíduos no início e segue aumentando a medida que crescem os valores ajustados.

O gráfico que avalia a Normalidade dos Resíduos, Sub.Fig. B, também não mostra um comportamento adequado para considerar o modelo como bom, pois é possível identificar que as caldas fogem e muito da reta de referência e do intervalo de confiança, inclusive, demonstrando haver pontos significativamente influentes que afetam o comportamento dos resíduos, logo, **se conclui que este não é um bom modelo para explicar o valor médio dos imóveis**.

Ainda assim, para fins de implementação das técnicas apresndidas até o momento, serão realizados os **Testes de Diagnóstico** para avaliação dos resultados, com a expectativa dos mesmos correoborarem com as interpretações obtidas através da análise gráfica.

<!-- Os dados mostram que existem dois valores atipicos que impedem uma análise mais apurada da homocedasticidade quando observados os valores médios ajustados dos imóveis. Percebe-se ainda que apenas um grupo de dados da região central da distribuição de Student apresenta certa normalidade, enquanto as "caldas" da distribuição afastam-se significativamente da reta de normalidade. -->

### Testes de diagnóstico

Serão realizados os Testes de Significância, como forma secundária de avaliação, sendo descritos os testes aplicados para fins didáticos, tendo em vista a conclusão obtida com as análises gráficas, sendo estes:

- Normalidade:
  - Teste de Kolmogorov-Smirnov
  - Teste de Shapiro-Wilks
- Homocedasticidade:
  - Teste de Goldfeld-Quandt
  - Teste de Breush-Pagan
  - Teste de Park
- Linearidae:
  - Teste F para linearidade
- Independência:
  - Teste para avaliação da independência dos resíduos

Sendo estes uam forma secundária de avaliação:

<!-- Pode-se ainda utilizar um conjunto de testes de diagnóstico para confirmar este novo teste de significância. -->
<!-- Como: -->

<!-- - Teste de Kolmogorov-Smirnov -->
<!-- - Teste de Shapiro-Wilks -->
<!-- - Teste de Goldfeld-Quandt -->
<!-- - Teste de Breush-Pagan -->
<!-- - Teste de Park -->
<!-- - Teste F para linearidade -->
<!-- - Teste para avaliação da independência dos resíduos -->


##### Teste de Kolmogorov-Smirnov

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false


t.ks = ks.test(dados_mFit_resid$.resid, "pnorm", mean(dados_mFit_resid$.resid), sd(dados_mFit_resid$.resid))

```

Avalia o grau de concordância entre a distribuição de um conjunto de valores observados e determinada distribuição teórica. Consiste em comparar a distribuição de frequência acumulada da distribuição teórica com aquela observada. Realizado o teste obteve-se um p-valor de aproximadamente `r round(t.ks[[2]][1],3)`, o que inviabiliza rejeitar a hipótese de que haja normalidade entre os dados, com um grau de confiabilidade minimamente razoável.

##### Teste de Shapiro-Wilks

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false

t.sw = shapiro.test(dados_mFit_resid$.resid)

```

O teste de Shapiro-Wilks é um procedimento alternativo ao teste de Kolmogorov-Smirnov para avaliar normalidade.
Realizado o teste obteve-se um p-valor de aproximadamente `r round(t.sw[[2]][1],3)`, o que, semelhantemente, inviabiliza rejeitar a hipótese de que haja normalidade entre os dados, com um grau de confiabilidade minimamente razoável.

##### Teste de Goldfeld-Quandt

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false

t.gq = gqtest(mLstat)

```

Esse teste envolve o ajuste de dois modelos de regressão, separando-se as observações das duas extremidades da distribuição da variável dependente.
Realizado o teste obteve-se um p-valor de aproximadamente `r round(t.gq[[5]][1],3)`, o que demanda rejeitar a hipótese de que haja homocedasticidade entre os dados, com um grau de confiabilidade de 95%. Entretanto, como o p-valor obtido é próximo do necessário para a rejeição da hipotese nula, cabe um novo teste para a confirmação do resultado obtido.

##### Teste de Breush-Pagan

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false

t.bp = bptest(mLstat, studentize = FALSE)
```

Esse teste é baseado no ajuste de um modelo de regressão em que a variável dependente é definida pelos resíduos do modelo de interesse.
Se grande parte da variabilidade dos resíduos não é explicada pelo modelo, então rejeita-se a hipótese de homocedasticidade.
Realizado o teste obteve-se um p-valor de aproximadamente `r round(t.bp[[4]][1],3)`, desta foram deve-se rejeitar a hipótese de que haja homocedasticidade entre os dados, com um grau de confiabilidade de 95%.

##### Teste de Park

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false
res2 <- (dados_mFit_resid$.resid)^2
t.p = summary(lm(res2 ~ dados$lstat))
```

Esse teste é baseado no ajuste de um modelo de regressão em que a variável dependente é definida pelos quadrados dos resíduos do modelo de interesse.
Nesse caso, se $\beta_1$ diferir significativamente de zero, rejeita-se a hipótese de homocedasticidade.
O valor de $\beta_1$ obtido no teste foi de `r round(t.p[[4]][2],3)` com p-valor de aproximadamente `r round(t.p[[4]][8],3)`.
Por esse teste não se deve rejeitar a hipótese de homocedasticidade, com confiabilidade de 95%.

##### Teste F para linearidade

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false
m_kmedias <- lm(dados$medv ~ factor(dados$lstat))
t.fl = anova(mLstat, m_kmedias)
```

O teste da falta de ajuste permite testar formalmente a adequação do ajuste do modelo de regressão.
Neste ponto assume-se que os pressupostos de normalidade, variância constante e independência são satisfeitos, como demosntrado pelos testes realizados. A ideia central para testar a linearidade é decompor SQRes em duas partes: erro puro e falta de ajuste que vão contribuir para a definição da estatística de teste F.
Realizado o teste obteve-se um valore de p-valor igual a `r round(t.fl[[6]][2],3)`, o que demanda a rejeição da hipótese que há uma relação linear entre as variáveis. 


##### Teste para avaliação da independência dos resíduos

```{r}
#| warning: false
#| eval: true
#| results: false
#| echo: false


t.dw = dwtest(mLstat)
```

Tendo em vista, o resultado obtido no teste anterior esse teste pode esclarecer ainda mais o ajuste do modelo.   
O teste para avaliação da independência dos resíduos é utilizado para detectar a presença de autocorrelação provenientes de análise de regressão.  Realizando o teste obteve-se um valor de p-valor aproximadadente igual a `r round(t.dw[[4]][1],3)`, indicando que se deve rejeitar a hipotese que não existe correlação serial entre os dados, com uma confiança de 95%.


# Conclusão

Da análise descritiva das variáveis deste banco de dados não se observa, situações impeditivas da proposta de modelamento por resgressão linear dos dados como forma de predizer o valor dos imóveis de Boston. Mesmo a análise de valores atípicos contribui com essa possibilidade uma vez que os valores candidatos a valores atípicos na verdade compõem o rol de dados relevantes uma vez que há enorme variedade em tipos, propósitos e status dos imóveis avaliados. Esses dados por suavez, representam um maior desafio ao modelamento a que esse trabalho se propõe.  
No teste da hipótese de correlação, todas as variáveis apresentaram significativa relação linear com o valor médio do imóvel, mesmo em casos que o coeficiente de determinação ($R^2$) se apresentou muito baixo.   
A implementação de técnicas de Regressão Linear Simples - RLS, para a variável explicativa que aparenta melhor possibilidade de explicação do Preço Médio dos Imóveis - Pop. Classe Baixa, não se mostrou muito eficiente como observado pela análise gráfica dos resíduos. Para melhor compreensão desta análise foram feitos testes de normalidade, homocedasticidade e de independência dos resíduos, de onde se concluiu que se deve rejeitar as hipoteses de normalidade, homocedasticidade e de independencia serial dos dados, confirmando assim o que a análise gráfica demonstrou.


# Referências

- Harrison, David & Rubinfeld, Daniel. (1978). Hedonic housing prices and the demand for clean air. Journal of Environmental Economics and Management. 5. 81-102. 10.1016/0095-0696(78)90006-2. 

- Belsley, David A. & Kuh, Edwin. & Welsch, Roy E. (1980). Regression diagnostics: identifying influential data and sources of collinearity. New York: Wiley.










